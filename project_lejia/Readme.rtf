{\rtf1\ansi\ansicpg1252\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ana_code: the major code for analytic purposes. \
	Note that For individual analytics of crime time in a day, crime month, and crime type, the codes are the same, but only the parameter (index of the row in the chart) changed, so I only included the screen shots and output file. \
	For combined analytics, similar situation also apply. So I also only changed parameter in the Hadoop but not in local java files. \
\
etl_code: the code to clean the original data sets. \
	Another version was included in the test codes because in later analytics we found that the original version does not satisfy what we want. \
\
Profiling_code: the code to count lines of the data sets, it helps us to see how many datas are cleaned out. Since data from kaggle are very clean, my result did not change too much. \
\
Input: it contains two files, one is the original data, and the other is data after cleaning. \
\
Output: it is the output of map reduce\
\
test_code: the code for test and did not finally get into use. \
\
Screenshots: for convenience and details, I save them to pdf version so that the viewers can have a thorough assess of what I did. \
\
Impala: I used impala to double check the map reduce results, and results are save as screen shots, stored in the screen shots directory. \
\
}